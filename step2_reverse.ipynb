{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '/anaconda/envs/py37_pytorch/lib/python3.7')\n",
    "sys.path.append('/anaconda/envs/py37_pytorch/lib/python3.7/site-packages')\n",
    "sys.path.append('/home/v-zeyyan/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import ResNet\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from dataset.ASdataset import AS_Data\n",
    "from dataset.ASdataset_obs_train_input import AS_Data_obs\n",
    "\n",
    "device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "reload(logging)\n",
    "logging.basicConfig(level=logging.INFO,#控制台打印的日志级别\n",
    "                    filename='logging.txt',\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\n",
    "                    format=\n",
    "                    '%(asctime)s : %(message)s',\n",
    "                    )\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# class Focal_loss_regression(nn.Module):\n",
    "#     def __init__(self,max_update=10,_lambda=2,):\n",
    "#         super(Focal_loss_regression,self).__init__()\n",
    "#         self._lambda = _lambda\n",
    "#         max_update = np.power(1/max_update,1/_lambda)\n",
    "#         max_update = 1/max_update\n",
    "#         max_update = 1/(max_update-1)\n",
    "#         self.max_update = max_update\n",
    "        \n",
    "#     def forward(self,pred,target):\n",
    "#         diff_abs = torch.abs(pred-target)\n",
    "#         diff_max = (1+self.max_update)*torch.max(diff_abs)\n",
    "# #         diff_max.detach()\n",
    "#         rate = torch.pow((1-1/diff_max*diff_abs)**self._lambda,-1)\n",
    "#         diff_abs = rate*diff_abs\n",
    "        \n",
    "# #         return diff_abs\n",
    "#         return torch.mean(diff_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v-zeyyan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is loading \n",
      "/AS_data/Conc_npy/TOTAL_2015_01_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_04_NO2_SO2_O3_PM25_PM10_CO__720_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_07_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_10_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "(558, 4, 182, 232)\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_01_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_04_720_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_07_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_10_744_07_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_01_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_04_720_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_07_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_10_744_34_182_232.npy   is loading\n",
      "[0, 535, 1052, 1587, 2122]\n",
      "2120\n",
      "test data is loading \n",
      "/AS_data/Conc_npy/TOTAL_2015_01_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_04_NO2_SO2_O3_PM25_PM10_CO__720_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_07_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_10_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "(186, 4, 182, 232)\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_01_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_04_720_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_07_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_10_744_07_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_01_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_04_720_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_07_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_10_744_34_182_232.npy   is loading\n",
      "[0, 163, 320, 483, 646]\n",
      "644\n"
     ]
    }
   ],
   "source": [
    "with open('config/cfg.yaml','r') as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "cfg = {**cfg['step1'],**cfg['share_cfg']}\n",
    "T = cfg['T']\n",
    "pollution = cfg['pollution']\n",
    "batch_size = cfg['batch_size']\n",
    "\n",
    "print('train data is loading ')\n",
    "Data = AS_Data(cfg['data_path'],left = cfg['train']['left'],right = cfg['train']['right'],window = T,pollution = pollution)\n",
    "trainloader = DataLoader(Data,batch_size=batch_size,shuffle=True)\n",
    "print(len(Data))\n",
    "\n",
    "print('test data is loading ')\n",
    "test_Data = AS_Data(cfg['data_path'],left = cfg['test']['left'],right = cfg['test']['right'],window = T,pollution = pollution)\n",
    "testloader = DataLoader(test_Data,batch_size=batch_size,shuffle=True)\n",
    "print(len(test_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.res_model_LSTM import res8\n",
    "from model.unet_model_LSTM import UNet\n",
    "from model.layers import Tensor_Parameter\n",
    "\n",
    "name = cfg['name']\n",
    "\n",
    "# name = 'res_2layer_correctdata'\n",
    "# test_model.load_state_dict(torch.load('model_save/res_2layer_9_epoch.t'))\n",
    "test_model = UNet(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,bilinear=False,pre_dim = len(pollution)) #+80\n",
    "# test_model = res8(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,pre_dim = len(pollution))\n",
    "# t2p = Tensor_Parameter()\n",
    "\n",
    "\n",
    "test_model.to(device)\n",
    "# t2p.to(device)\n",
    "# criterion = torch.nn.L1Loss()\n",
    "# optimizer = torch.optim.SGD(t2p.parameters(),lr=1)\n",
    "# optimizer = torch.optim.Adam(t2p.parameters(),lr=1e-1)\n",
    "test_model.load_state_dict(torch.load(name))\n",
    "# test_model.load_state_dict(torch.load('model_save/o3_best_unet2_1month_65_epoch.t'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet_model_LSTM import ReverseModel\n",
    "reverse_model = ReverseModel(cfg['meteorological_dim'],cfg['grid_dim'],pre_dim = len(pollution),T=T,em_dim=cfg['emission_dim'])\n",
    "reverse_model.to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "reverse_optimizer = torch.optim.Adam(reverse_model.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the reverse model\n",
      "-----------0-----------\n",
      "Direct Loss: 0.4258710741996765; F Loss: 1.5374720096588135\n",
      "Direct Loss: 0.2905590236186981; F Loss: 1.4596586227416992\n",
      "Direct Loss: 0.45922431349754333; F Loss: 1.511000633239746\n",
      "Direct Loss: 0.39173874258995056; F Loss: 1.2589704990386963\n",
      "Direct Loss: 0.36180102825164795; F Loss: 1.3997191190719604\n",
      "Direct Loss: 0.3806927800178528; F Loss: 1.2660657167434692\n",
      "Direct Loss: 0.3725880980491638; F Loss: 1.224298119544983\n",
      "Direct Loss: 0.3255261480808258; F Loss: 1.470232367515564\n",
      "Direct Loss: 0.4679259657859802; F Loss: 1.1564289331436157\n",
      "Direct Loss: 0.4427716135978699; F Loss: 1.179296851158142\n",
      "Direct Loss: 0.41670459508895874; F Loss: 1.15873122215271\n",
      "Direct Loss: 0.3988106846809387; F Loss: 1.2057125568389893\n",
      "Direct Loss: 0.4703340232372284; F Loss: 1.2714154720306396\n",
      "Direct Loss: 0.3729773163795471; F Loss: 1.2024688720703125\n",
      "Direct Loss: 0.4451914429664612; F Loss: 1.190292477607727\n",
      "Direct Loss: 0.26851579546928406; F Loss: 1.4180980920791626\n",
      "Direct Loss: 0.4490545094013214; F Loss: 1.3484253883361816\n",
      "Direct Loss: 0.39706265926361084; F Loss: 1.3196008205413818\n",
      "Direct Loss: 0.42210254073143005; F Loss: 1.4744080305099487\n",
      "Direct Loss: 0.4186515212059021; F Loss: 1.1508862972259521\n",
      "Direct Loss: 0.3813265264034271; F Loss: 1.2665499448776245\n",
      "Direct Loss: 0.33990463614463806; F Loss: 1.1930822134017944\n",
      "Direct Loss: 0.44929784536361694; F Loss: 1.2951147556304932\n",
      "Direct Loss: 0.3640512228012085; F Loss: 1.2587980031967163\n",
      "Direct Loss: 0.3689497709274292; F Loss: 1.2640565633773804\n",
      "Average Training Loss: Direct Loss: 0.38522639870643616; F Loss: 1.3208369016647339\n",
      "********Evaluating*********\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 15.90 GiB total capacity; 11.84 GiB already allocated; 2.23 GiB free; 12.88 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-03cec7a5dfd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_metro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_metro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mem_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_metro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mnew_em\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mem_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_em\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetro\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/InventoryOptimization/model/unet_model_LSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, metrod, grid, all_label)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m#         print(f'h0 shape: {h0.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;31m#         print(f'c0 shape: {c0.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_metrod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#hn num_layers*(B*H*W)*rnn_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;31m#         print(f'hn shape: {hn.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;31m#         print(f'cn shape: {cn.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.42 GiB (GPU 0; 15.90 GiB total capacity; 11.84 GiB already allocated; 2.23 GiB free; 12.88 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "print('Train the reverse model')\n",
    "for epoch in range(1):\n",
    "    print('-----------{}-----------'.format(epoch))\n",
    "    ls = []\n",
    "    direct_ls = []\n",
    "    reverse_model.train()\n",
    "    test_model.train()\n",
    "    count = 0\n",
    "    for idx,i in enumerate(trainloader):\n",
    "        input,grid,yt_1,label,next_label, next_metro = i\n",
    "        em = input[:,:,:cfg['emission_dim'],:,:]\n",
    "        metro = input[:,:,cfg['emission_dim']:,:,:]\n",
    "        input,em,metro,grid,yt_1,label,next_label, next_metro = input.to(device),em.to(device),metro.to(device),grid.to(device),yt_1.to(device),label.to(device),next_label.to(device),next_metro.to(device)\n",
    "        em_pred = reverse_model(next_metro,grid,next_label)\n",
    "        new_em = torch.cat([em[:,:-1,:,:,:],em_pred.detach()],dim=1)\n",
    "        x_pred = torch.cat([new_em,metro],dim=2)\n",
    "        reverse_optimizer.zero_grad()\n",
    "        label_pred = test_model(x_pred,grid,yt_1) #输入yt_1但是模型中没用\n",
    "        loss = criterion(label_pred,label)\n",
    "        loss.backward()\n",
    "        reverse_optimizer.step()\n",
    "        direct_loss = criterion(em_pred.detach(),em[:,-1:,:,:,:])\n",
    "        count += 1\n",
    "        if count%40 == 0: print(f'Direct Loss: {direct_loss.cpu().data}; F Loss: {loss.cpu().data}')\n",
    "        ls.append(loss.cpu().data)\n",
    "        direct_ls.append(direct_loss.cpu().data)\n",
    "    print(f'Average Training Loss: Direct Loss: {np.mean(np.array(direct_ls))}; F Loss: {np.mean(np.array(ls))}')\n",
    "    eval_loss = []\n",
    "    eval_direct_loss = []\n",
    "    print('********Evaluating*********')\n",
    "    for idx,i in enumerate(testloader):\n",
    "        input,grid,yt_1,label,next_label, next_metro = i\n",
    "        em = input[:,:,:cfg['emission_dim'],:,:]\n",
    "        metro = input[:,:,cfg['emission_dim']:,:,:]\n",
    "\n",
    "        input,em,metro,grid,yt_1,label,next_label, next_metro = input.to(device),em.to(device),metro.to(device),grid.to(device),yt_1.to(device),label.to(device),next_label.to(device),next_metro.to(device)\n",
    "        em_pred = reverse_model(next_metro,grid,next_label)\n",
    "        new_em = torch.cat([em[:,:-1,:,:,:],em_pred.detach()],dim=1)\n",
    "        x_pred = torch.cat([new_em,metro],dim=2)\n",
    "        label_pred = test_model(x_pred,grid,yt_1) #输入yt_1但是模型中没用\n",
    "        loss = criterion(label_pred,label)\n",
    "        direct_loss = criterion(em_pred.detach(),em[:,-1:,:,:,:])\n",
    "        eval_loss.append(loss.cpu().data)\n",
    "        eval_direct_loss.append(direct_loss.cpu().data)\n",
    "    print(f'------------Evaluating: Direct Loss: {np.mean(np.array(eval_direct_loss))}; F Loss: {np.mean(np.array(eval_loss))}')\n",
    "    torch.save(reverse_model.cpu().state_dict(),'model_save/reverse_norm_4month_f_loss.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train the reverse model')\n",
    "for epoch in range(1):\n",
    "    print('-----------{}-----------'.format(epoch))\n",
    "    ls = []\n",
    "    reverse_model.train()\n",
    "    for idx,i in enumerate(trainloader):\n",
    "        input,grid,yt_1,label,all_label = i\n",
    "        em = input[:,:,:7,:,:]\n",
    "        metro = input[:,:,7:,:,:]\n",
    "#         print(em.shape)\n",
    "#         print(metro.shape)\n",
    "        input,em,metro,grid,yt_1,label,all_label = input.to(device),em.to(device),metro.to(device),grid.to(device),yt_1.to(device),label.to(device),all_label.to(device)\n",
    "        em_pred = reverse_model(metro,grid,all_label)\n",
    "        em_label = em[:,-1:,:,:,:]\n",
    "        reverse_optimizer.zero_grad()\n",
    "        loss = criterion(em_pred,em_label)\n",
    "        loss.backward()\n",
    "        reverse_optimizer.step()\n",
    "        print('*'*20)\n",
    "        print(loss.cpu().data)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
