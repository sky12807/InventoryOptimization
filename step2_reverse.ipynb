{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '/anaconda/envs/py37_pytorch/lib/python3.7')\n",
    "sys.path.append('/anaconda/envs/py37_pytorch/lib/python3.7/site-packages')\n",
    "sys.path.append('/home/v-zeyyan/.local/lib/python3.6/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import ResNet\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from dataset.ASdataset import AS_Data\n",
    "from dataset.ASdataset_obs_train_input import AS_Data_obs\n",
    "\n",
    "device = torch.device(\"cuda:1\"  if torch.cuda.is_available() else \"cpu\")\n",
    "reload(logging)\n",
    "logging.basicConfig(level=logging.INFO,#控制台打印的日志级别\n",
    "                    filename='log/step2-reverse-model-logging.txt',\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\n",
    "                    format=\n",
    "                    '%(asctime)s : %(message)s',\n",
    "                    )\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# class Focal_loss_regression(nn.Module):\n",
    "#     def __init__(self,max_update=10,_lambda=2,):\n",
    "#         super(Focal_loss_regression,self).__init__()\n",
    "#         self._lambda = _lambda\n",
    "#         max_update = np.power(1/max_update,1/_lambda)\n",
    "#         max_update = 1/max_update\n",
    "#         max_update = 1/(max_update-1)\n",
    "#         self.max_update = max_update\n",
    "        \n",
    "#     def forward(self,pred,target):\n",
    "#         diff_abs = torch.abs(pred-target)\n",
    "#         diff_max = (1+self.max_update)*torch.max(diff_abs)\n",
    "# #         diff_max.detach()\n",
    "#         rate = torch.pow((1-1/diff_max*diff_abs)**self._lambda,-1)\n",
    "#         diff_abs = rate*diff_abs\n",
    "        \n",
    "# #         return diff_abs\n",
    "#         return torch.mean(diff_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-6f6bd9445ea2>:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is loading \n",
      "/AS_data/Conc_npy/TOTAL_2015_01_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_04_NO2_SO2_O3_PM25_PM10_CO__720_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_07_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_10_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "(744, 4, 182, 232)\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_01_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_04_720_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_07_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_10_744_07_182_232.npy   is loading\n",
      "(744, 7, 182, 232)\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_01_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_04_720_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_07_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_10_744_34_182_232.npy   is loading\n",
      "[0, 721, 1418, 2139, 2860]\n",
      "2858\n"
     ]
    }
   ],
   "source": [
    "with open('config/cfg.yaml','r') as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "cfg = {**cfg['step2'],**cfg['share_cfg']}\n",
    "\n",
    "T = cfg['T']\n",
    "pollution = cfg['pollution']\n",
    "batch_size = cfg['batch_size']\n",
    "EM_idx = np.array(cfg['EM_idx'])\n",
    "\n",
    "print('train data is loading ')\n",
    "Data = AS_Data(cfg['data_path'],left = cfg['train']['left'],right = cfg['train']['right'],window = T,EM_idx = EM_idx,pollution = pollution)\n",
    "trainloader = DataLoader(Data,batch_size=batch_size,shuffle=True)\n",
    "print(len(Data))\n",
    "\n",
    "# print('test data is loading ')\n",
    "# test_Data = AS_Data(cfg['data_path'],left = cfg['test']['left'],right = cfg['test']['right'],window = T,pollution = pollution)\n",
    "# testloader = DataLoader(test_Data,batch_size=batch_size,shuffle=True)\n",
    "# print(len(test_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.res_model_LSTM import res8\n",
    "from model.unet_model_LSTM import UNet\n",
    "from model.layers import Tensor_Parameter\n",
    "\n",
    "name = cfg['name']\n",
    "\n",
    "# name = 'res_2layer_correctdata'\n",
    "# test_model.load_state_dict(torch.load('model_save/res_2layer_9_epoch.t'))\n",
    "test_model = UNet(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,bilinear=False,pre_dim = len(pollution)) #+80\n",
    "# test_model = res8(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,pre_dim = len(pollution))\n",
    "# t2p = Tensor_Parameter()\n",
    "\n",
    "\n",
    "test_model.to(device)\n",
    "# t2p.to(device)\n",
    "# criterion = torch.nn.L1Loss()\n",
    "# optimizer = torch.optim.SGD(t2p.parameters(),lr=1)\n",
    "# optimizer = torch.optim.Adam(t2p.parameters(),lr=1e-1)\n",
    "test_model.load_state_dict(torch.load('model_save/model_F_35_epoch.t'))\n",
    "# test_model.load_state_dict(torch.load('model_save/o3_best_unet2_1month_65_epoch.t'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.unet_model_LSTM import ReverseModel\n",
    "reverse_model = ReverseModel(cfg['meteorological_dim'],cfg['grid_dim'],pre_dim = len(pollution),T=T,em_dim=cfg['emission_dim'])\n",
    "reverse_model.to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "reverse_optimizer = torch.optim.Adam(reverse_model.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logging(string):\n",
    "    print(string)\n",
    "    logging.info(string)\n",
    "\n",
    "\n",
    "def score(testloader):\n",
    "    eval_loss = []\n",
    "    eval_direct_loss = []\n",
    "    \n",
    "    print_logging('********Evaluating*********')\n",
    "    for idx,i in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            indexes,input1_24,grid,yt_1,label_24,next_label24_47, next_metro24_47 = [j.to(device) for j in i]\n",
    "            em1_24 = input1_24[:,:,:cfg['emission_dim'],:,:]\n",
    "            metro1_24 = input1_24[:,:,cfg['emission_dim']:,:,:]\n",
    "\n",
    "            em_24_pred = reverse_model(next_metro24_47,grid,next_label24_47)\n",
    "            new_em = torch.cat([em1_24[:,:-1,:,:,:],em_24_pred],dim=1)\n",
    "            new_em = torch.cat([new_em,metro1_24],dim=2)\n",
    "\n",
    "            label_pred_24 = test_model(new_em,grid,yt_1) #输入yt_1但是模型中没用\n",
    "\n",
    "            direct_loss = criterion(em_24_pred.detach(),em1_24[:,-1:,:,:,:])\n",
    "            \n",
    "            cur_loss = []\n",
    "            for j in range(label_24.shape[1]):\n",
    "                loss = criterion(label_pred_24[:,j],label_24[:,j])\n",
    "                cur_loss.append(loss.cpu().data)\n",
    "            eval_loss.append(cur_loss)\n",
    "            \n",
    "            eval_direct_loss.append(direct_loss.cpu().data)\n",
    "        \n",
    "    print_logging(f'------------Evaluating: Direct Loss: {np.mean(np.array(eval_direct_loss))};')\n",
    "    print_logging(' F Loss for pm25 o3 no2 so2 ,{}, {}, {},{}'.format(*np.mean(np.array(eval_loss),axis = 0)))\n",
    "    \n",
    "    \n",
    "    return np.mean(np.array(eval_direct_loss)),*np.mean(np.array(eval_loss),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------1-----------\n",
      "         Direct Loss: 0.45309576392173767; F Loss: 1.5053843259811401\n",
      "         Direct Loss: 0.4092447757720947; F Loss: 1.5169936418533325\n",
      "         Direct Loss: 0.3957236409187317; F Loss: 1.4778181314468384\n",
      "         Direct Loss: 0.39836347103118896; F Loss: 1.492730736732483\n",
      "         Direct Loss: 0.39708754420280457; F Loss: 1.4856045246124268\n",
      "         Direct Loss: 0.4001055359840393; F Loss: 1.4908708333969116\n",
      "         Direct Loss: 0.4062238931655884; F Loss: 1.4854233264923096\n",
      "         Direct Loss: 0.4005134105682373; F Loss: 1.4770941734313965\n",
      "         Direct Loss: 0.3992975354194641; F Loss: 1.4892369508743286\n",
      "         Direct Loss: 0.3994910418987274; F Loss: 1.484359860420227\n",
      "         Direct Loss: 0.3972516655921936; F Loss: 1.4854202270507812\n",
      "         Direct Loss: 0.39556261897087097; F Loss: 1.4837602376937866\n",
      "         Direct Loss: 0.39538225531578064; F Loss: 1.484139323234558\n",
      "         Direct Loss: 0.39653104543685913; F Loss: 1.4850088357925415\n",
      "         Direct Loss: 0.39760610461235046; F Loss: 1.4855055809020996\n",
      "         Direct Loss: 0.4002546966075897; F Loss: 1.4872537851333618\n",
      "         Direct Loss: 0.40260785818099976; F Loss: 1.4899541139602661\n",
      "         Direct Loss: 0.40584680438041687; F Loss: 1.4857763051986694\n",
      "         Direct Loss: 0.41101863980293274; F Loss: 1.486701250076294\n",
      "         Direct Loss: 0.41648975014686584; F Loss: 1.4849203824996948\n",
      "         Direct Loss: 0.4231317937374115; F Loss: 1.4833800792694092\n",
      "         Direct Loss: 0.4304944574832916; F Loss: 1.482893466949463\n",
      "         Direct Loss: 0.437761127948761; F Loss: 1.4817301034927368\n",
      "         Direct Loss: 0.4455222487449646; F Loss: 1.4838404655456543\n",
      "         Direct Loss: 0.45402365922927856; F Loss: 1.4826399087905884\n",
      "         Direct Loss: 0.46245071291923523; F Loss: 1.4846060276031494\n",
      "         Direct Loss: 0.47050318121910095; F Loss: 1.484056830406189\n",
      "         Direct Loss: 0.4786805212497711; F Loss: 1.4856550693511963\n",
      "Average Training Loss: Direct Loss: 0.4838167428970337; F Loss: 1.4868232011795044\n",
      "********Evaluating*********\n",
      "------------Evaluating: Direct Loss: 0.5645116567611694;\n",
      " F Loss for pm25 o3 no2 so2 ,2.548222541809082, 2.7971091270446777, 0.4284782409667969,0.3317365050315857\n",
      "-----------2-----------\n",
      "         Direct Loss: 0.5804247856140137; F Loss: 1.4537118673324585\n"
     ]
    }
   ],
   "source": [
    "score(trainloader)\n",
    "print_logging('Train the reverse model')\n",
    "\n",
    "\n",
    "for epoch in range(1,100):\n",
    "    print_logging('-----------{}-----------'.format(epoch))\n",
    "    ls = []\n",
    "    direct_ls = []\n",
    "    reverse_model.train()\n",
    "    test_model.train()\n",
    "    count = 0\n",
    "    for idx,i in enumerate(trainloader):\n",
    "        indexes,input1_24,grid,yt_1,label_24,next_label24_47, next_metro24_47 = [j.to(device) for j in i]\n",
    "        em1_24 = input1_24[:,:,:cfg['emission_dim'],:,:]\n",
    "        metro1_24 = input1_24[:,:,cfg['emission_dim']:,:,:]\n",
    "        \n",
    "        reverse_optimizer.zero_grad()\n",
    "        \n",
    "        em_24_pred = reverse_model(next_metro24_47,grid,next_label24_47)\n",
    "        new_em = torch.cat([em1_24[:,:-1,:,:,:],em_24_pred],dim=1)\n",
    "        \n",
    "        new_input = torch.cat([new_em,metro1_24],dim=2)\n",
    "        \n",
    "        label_pred_24 = test_model(new_input,grid,yt_1) #输入yt_1但是模型中没用\n",
    "        loss = criterion(label_pred_24,label_24)\n",
    "        loss.backward()\n",
    "        reverse_optimizer.step()\n",
    "        direct_loss = criterion(em_24_pred.detach(),em1_24[:,-1:,:,:,:])\n",
    "        count += 1\n",
    "        if count%100 == 0:print(f'         Direct Loss: {np.mean(np.array(direct_ls))}; F Loss: {np.mean(np.array(ls))}')\n",
    "\n",
    "        ls.append(loss.cpu().data)\n",
    "        direct_ls.append(direct_loss.cpu().data)\n",
    "        \n",
    "        \n",
    "        ### update input data\n",
    "        Data.update(indexes,new_em)\n",
    "        \n",
    "    print_logging(f'Average Training Loss: Direct Loss: {np.mean(np.array(direct_ls))}; F Loss: {np.mean(np.array(ls))}')\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        torch.save(reverse_model.cpu().state_dict(),'model_save/model_G_{}_epoch.t'.format(epoch))\n",
    "        reverse_model.to(device)\n",
    "    \n",
    "    score(trainloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
