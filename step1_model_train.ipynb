{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append( '/anaconda/envs/py37_pytorch/lib/python3.7')\n",
    "# sys.path.append('/anaconda/envs/py37_pytorch/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import yaml\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.models import ResNet\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "import logging\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "reload(logging)\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,#控制台打印的日志级别\n",
    "                    filename='logging.txt',\n",
    "                    filemode='a',##模式，有w和a，w就是写模式，每次都会重新写日志，覆盖之前的日志\n",
    "                    #a是追加模式，默认如果不写的话，就是追加模式\n",
    "                    format=\n",
    "                    '%(asctime)s : %(message)s',\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "from dataset.ASdataset import AS_Data\n",
    "from dataset.ASdataset_obs_train_input import AS_Data_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-fa3df4bc90e2>:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data is loading \n",
      "/AS_data/Conc_npy/TOTAL_2015_01_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_04_NO2_SO2_O3_PM25_PM10_CO__720_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_07_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_10_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "(558, 4, 182, 232)\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_01_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_04_720_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_07_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_10_744_07_182_232.npy   is loading\n",
      "(558, 7, 182, 232)\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_01_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_04_720_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_07_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_10_744_34_182_232.npy   is loading\n",
      "[0, 535, 1052, 1587, 2122]\n",
      "2120\n",
      "test data is loading \n",
      "/AS_data/Conc_npy/TOTAL_2015_01_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_04_NO2_SO2_O3_PM25_PM10_CO__720_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_07_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "/AS_data/Conc_npy/TOTAL_2015_10_NO2_SO2_O3_PM25_PM10_CO__744_6_182_232.npy   is loading\n",
      "(744, 4, 182, 232)\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_01_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_04_720_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_07_744_07_182_232.npy   is loading\n",
      "/AS_data/zeyuan_folder/concat_data/rest_EM_2015_10_744_07_182_232.npy   is loading\n",
      "(744, 7, 182, 232)\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_01_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_04_720_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_07_744_34_182_232.npy   is loading\n",
      "/AS_data/METCRO2D_npy/METCRO2D_2015_10_744_34_182_232.npy   is loading\n",
      "[0, 721, 1418, 2139, 2860]\n",
      "2858\n"
     ]
    }
   ],
   "source": [
    "with open('config/cfg.yaml','r') as f:\n",
    "    cfg = yaml.load(f)\n",
    "\n",
    "cfg = {**cfg['step1'],**cfg['share_cfg']}\n",
    "T = cfg['T']\n",
    "pollution = cfg['pollution']\n",
    "batch_size = cfg['batch_size']\n",
    "\n",
    "print('train data is loading ')\n",
    "Data = AS_Data(cfg['data_path'],left = cfg['train']['left'],right = cfg['train']['right'],window = T,pollution = pollution)\n",
    "trainloader = DataLoader(Data,batch_size=batch_size,shuffle=True)\n",
    "print(len(Data))\n",
    "\n",
    "print('test data is loading ')\n",
    "test_Data = AS_Data(cfg['data_path'],left = cfg['test']['left'],right = cfg['test']['right'],window = T,pollution = pollution)\n",
    "testloader = DataLoader(test_Data,batch_size=batch_size,shuffle=True)\n",
    "print(len(test_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.res_model_LSTM import res8\n",
    "from model.unet_model_LSTM import UNet\n",
    "\n",
    "# test_model = res8(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,pre_dim = len(pollution)) #+5*16\n",
    "name = cfg['name']\n",
    "test_model = UNet(cfg['meteorological_dim']+cfg['emission_dim'],cfg['grid_dim'],T=T,bilinear=False,pre_dim = len(pollution)) #+80\n",
    "# name = cfg['name']\n",
    "test_model.load_state_dict(torch.load('model_save/model_F_35_epoch.t'))\n",
    "\n",
    "test_model.to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(test_model.parameters(),lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model,loader,criterion= nn.L1Loss(),percent = False):\n",
    "    model.eval()\n",
    "    ls = []\n",
    "    for idx,i in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            indexes,input,grid,yt_1,label,next_label, next_metro = [j.to(device) for j in i]\n",
    "#             input,grid,yt_1,label,next_label, next_metro = input.to(device),grid.to(device),yt_1.to(device),label.to(device),next_label.to(device),next_metro.to(device)\n",
    "            y_pred = model(input,grid,yt_1)\n",
    "            \n",
    "#             if NORM_METHOD == 1:\n",
    "#                 y_pred = y_pred * (dic['max'] - dic['min']) + dic['min']\n",
    "#                 label = label * (dic['max'] - dic['min']) + dic['min']\n",
    "#             elif NORM_METHOD == 2:\n",
    "#                 y_pred = (y_pred + dic['min']) * dic['std'] + dic['mean']\n",
    "#                 label = label * (dic['max'] - dic['min']) + dic['min']\n",
    "            \n",
    "            cur_loss = []\n",
    "            for j in range(label.shape[1]):\n",
    "                if percent:\n",
    "                    for esp in [0.1,1,4,8,12,16]:\n",
    "                        loss = torch.mean(torch.abs(y_pred[:,j]-label[:,j])/(label[:,j]+esp))\n",
    "                        cur_loss.append(loss.cpu().data)\n",
    "                else:\n",
    "                    loss = criterion(y_pred[:,j],label[:,j])\n",
    "                    cur_loss.append(loss.cpu().data)\n",
    "\n",
    "            ls.append(cur_loss)\n",
    "            \n",
    "    return np.mean(np.array(ls),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1765795 , 2.6870308 , 0.36613306, 0.27721682], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(test_model,testloader,criterion = nn.L1Loss()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '''\n",
    "Apparent consumption of coal, oil and natural gas in China in 2013\n",
    "was 3.84 Gt, 401.16 Mt and 131.30 Gm3\n",
    ", respectively. Between 1997\n",
    "and 2012, we estimate that cumulative energy consumption was 10% greater than the national statistics and 4% lower than provincial statistics (Extended Data Fig. 2). In addition, our results indicate a higher\n",
    "annual growth rate of energy consumption than national statistics\n",
    "between 2000 and 2010 (9.9% yr21 instead of 8.8% yr21\n",
    "); the high\n",
    "growth rate is consistent with satellite observations of NOx\n",
    "20,21,\n",
    "although NOx to fuel emission factors change with time as well.\n",
    "Given the large fraction of CO2 emissions from coal combustion\n",
    "(80% between 2000 and 2013), estimates of total emissions are heavily\n",
    "dependent on the emission factors used to assess coal emissions. Thus,\n",
    "we re-evaluate each of the variables that determine these emission\n",
    "factors. The mean total carbon content of raw coal samples from\n",
    "4,243 state-owned Chinese coal mines (4,243 mines represent 36%\n",
    "of Chinese coal production in 2011)22 (Fig. 1) is 58.45% (Fig. 2a),\n",
    "and the production-weighted total carbon content is 53.34%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Apparent consumption of coal, oil and natural gas in China in 2013 was 3.84 Gt, 401.16 Mt and 131.30 Gm3 , respectively. Between 1997 and 2012, we estimate that cumulative energy consumption was 10% greater than the national statistics and 4% lower than provincial statistics (Extended Data Fig. 2). In addition, our results indicate a higher annual growth rate of energy consumption than national statistics between 2000 and 2010 (9.9% yr21 instead of 8.8% yr21 ); the high growth rate is consistent with satellite observations of NOx 20,21, although NOx to fuel emission factors change with time as well. Given the large fraction of CO2 emissions from coal combustion (80% between 2000 and 2013), estimates of total emissions are heavily dependent on the emission factors used to assess coal emissions. Thus, we re-evaluate each of the variables that determine these emission factors. The mean total carbon content of raw coal samples from 4,243 state-owned Chinese coal mines (4,243 mines represent 36% of Chinese coal production in 2011)22 (Fig. 1) is 58.45% (Fig. 2a), and the production-weighted total carbon content is 53.34% '"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 1000\n",
    "early_stop = 15\n",
    "early_cnt = 0\n",
    "for epoch in range(5,40):\n",
    "#     logging.info('-----------{}-----------'.format(epoch))\n",
    "    print('-----------{}-----------'.format(epoch))\n",
    "    ls = []\n",
    "    \n",
    "    test_model.train()\n",
    "    for idx,i in enumerate(trainloader):\n",
    "        indexes,input,grid,yt_1,label,next_label, next_metro = [j.to(device) for j in i]\n",
    "        \n",
    "        y_pred = test_model(input,grid,yt_1)\n",
    "#         print('*'*20)\n",
    "        assert y_pred.shape == label.shape\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(y_pred,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ls.append(loss.cpu().data)\n",
    "        if len(ls)%40==0:\n",
    "            logging.info('epoch {} cur loss {}'.format(epoch,np.mean(ls)))\n",
    "            print('epoch {} cur loss {}'.format(epoch,np.mean(ls)))\n",
    "#         torch.save(test_model.cpu().state_dict(),'model_save/test.t')\n",
    "    \n",
    "#     logging.info('epoch {} cur loss {}'.format(epoch,np.mean(ls)))\n",
    "    print('epoch {} cur loss {}'.format(epoch,np.mean(ls)))\n",
    "    test_score_L1 = score(test_model,testloader,criterion = nn.L1Loss()) \n",
    "#     logging.info('-------------cur test loss L1:  {}'.format(','.join([str(s) for s in test_score_L1])))\n",
    "    print('-------------cur test loss L1:  {}'.format(','.join([str(s) for s in test_score_L1])))\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        torch.save(test_model.cpu().state_dict(),'model_save/model_F_{}_epoch.t'.format(epoch))\n",
    "        test_model.to(device)\n",
    "        \n",
    "    if np.sum(test_score_L1)<best_score:\n",
    "        early_cnt = 0\n",
    "        best_score = np.sum(test_score_L1)\n",
    "        torch.save(test_model.cpu().state_dict(),name)\n",
    "        test_model.to(device)\n",
    "    else:\n",
    "        early_cnt += 1\n",
    "        if early_cnt>=early_stop:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.load_state_dict(torch.load(name))\n",
    "\n",
    "# test_model = res8(51+34+16,27,[3],T=48)\n",
    "\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '''Jan. & 10.60 & 6.50 & 10.76 & 5.56 & 19.30 & 9.20 & 13.95 & 6.28 \\\\ \\hline\n",
    "        Apr. & 13.90 & 4.70 & 12.16 & 6.61 & 13.30 & 7.20 & 12.85 & 7.56 \\\\ \\hline\n",
    "        Jul. & 16.50 & 6.90 & 6.93 & 6.05 & 29.20 & 7.90 & 8.60 & 6.67 \\\\ \\hline\n",
    "        Oct. & 14.90 & 11.20 & 9.70 & 5.64 & 19.00 & 9.60 & 11.80 & 5.88\\\\ \\hline \n",
    "        Average & 13.97&7.32&9.88&5.96&20.20&8.47&11.8&6.59 \\\\ \\hline \\hline'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '''Jan. \t10.76\t5.56\t10.6\t6.5\t13.95\t6.28\t19.3\t9.2\n",
    "        Apr. \t12.16\t6.61\t13.9\t4.7\t12.85\t7.56\t13.3\t7.2\n",
    "        Jul. \t6.93\t6.05\t16.5\t6.9\t8.6\t6.67\t29.2\t7.9\n",
    "        Oct. \t9.7\t5.64\t14.9\t11.2\t11.8\t5.88\t19\t9.6\n",
    "        Average \t9.88\t5.96\t13.97\t7.32\t11.8\t6.59\t20.2\t8.47\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan.  & 10.76 & 5.56 & 10.6 & 6.5 & 13.95 & 6.28 & 19.3 & 9.2\n",
      "        Apr.  & 12.16 & 6.61 & 13.9 & 4.7 & 12.85 & 7.56 & 13.3 & 7.2\n",
      "        Jul.  & 6.93 & 6.05 & 16.5 & 6.9 & 8.6 & 6.67 & 29.2 & 7.9\n",
      "        Oct.  & 9.7 & 5.64 & 14.9 & 11.2 & 11.8 & 5.88 & 19 & 9.6\n",
      "        Average  & 9.88 & 5.96 & 13.97 & 7.32 & 11.8 & 6.59 & 20.2 & 8.47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(string.replace('\\t',' & '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan. \t 10.60 \t 6.50 \t 10.76 \t 5.56 \t 19.30 \t 9.20 \t 13.95 \t 6.28 \\ \\hline\n",
      "        Apr. \t 13.90 \t 4.70 \t 12.16 \t 6.61 \t 13.30 \t 7.20 \t 12.85 \t 7.56 \\ \\hline\n",
      "        Jul. \t 16.50 \t 6.90 \t 6.93 \t 6.05 \t 29.20 \t 7.90 \t 8.60 \t 6.67 \\ \\hline\n",
      "        Oct. \t 14.90 \t 11.20 \t 9.70 \t 5.64 \t 19.00 \t 9.60 \t 11.80 \t 5.88\\ \\hline \n",
      "        Average \t 13.97\t7.32\t9.88\t5.96\t20.20\t8.47\t11.8\t6.59 \\ \\hline \\hline\n"
     ]
    }
   ],
   "source": [
    "for i in string.split('\\n'):\n",
    "    print('\\t'.join(i.split('&')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16,7.0)\n",
    "\n",
    "test_model.eval()\n",
    "air_idx = 0 #pm25\n",
    "\n",
    "for idx,i in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        input,grid,yt_1,label = i\n",
    "        input = torch.squeeze(input,1)\n",
    "        input,grid,yt_1,label = input.to(device),grid.to(device),yt_1.to(device),label.to(device)\n",
    "        y_pred = test_model(input,grid,yt_1)\n",
    "        \n",
    "        label = label.cpu().numpy()\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "        print(label.shape)\n",
    "        print(y_pred.shape)\n",
    "        print(label)\n",
    "        for b_idx in range(len(label)):\n",
    "            \n",
    "            plt.subplot(1,3,1)\n",
    "            image1 = label[b_idx,air_idx]\n",
    "            max_label = np.max(image1)\n",
    "            image_show(image1,'label',base=max_label)\n",
    "            \n",
    "            plt.subplot(1,3,2)\n",
    "            image2 = y_pred[b_idx,air_idx]\n",
    "            image_show(image2,'pred',base=max_label)\n",
    "            \n",
    "            plt.subplot(1,3,3)\n",
    "            image3 = np.abs(image2-image1)\n",
    "            image_show(image3,'diff',base=max_label)\n",
    "            plt.show()\n",
    "        if idx>5:break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
